#!/usr/bin/env python3
"""
Test POTUS Predictions tournament discovery and forecasting.
"""
import asyncio
import os
from datetime import datetime

# Set up environment
os.environ['GITHUB_ACTIONS'] = 'true'

async def test_potus_tournament():
    """Test POTUS tournament discovery and forecasting."""
    try:
        from forecasting_tools import MetaculusApi, BinaryQuestion
        from forecasting_tools.helpers.metaculus_api import ApiFilter
        from fallback_llm import create_research_fallback_llm, create_forecasting_fallback_llm, create_synthesis_fallback_llm

        print("ğŸ¯ TESTING POTUS PREDICTIONS TOURNAMENT")
        print("=" * 50)

        # Check API keys
        api_key = os.getenv('OPENROUTER_API_KEY')
        metaculus_token = os.getenv('METACULUS_TOKEN')

        if not api_key:
            print("âŒ OPENROUTER_API_KEY is not set!")
            return False

        if not metaculus_token:
            print("âŒ METACULUS_TOKEN is not set!")
            return False

        print(f"âœ… API keys configured")

        # Step 1: Try to find POTUS tournament questions
        print(f"\nğŸ“Š STEP 1: FINDING POTUS TOURNAMENT QUESTIONS")

        # Test specific question ID 39988 first
        print(f"ğŸ” Testing specific POTUS question ID 39988...")
        try:
            all_questions = await MetaculusApi.get_questions_matching_filter(
                ApiFilter(allowed_statuses=["open"], number_of_questions=100)
            )

            potus_questions = []
            found_specific = False

            for q in all_questions:
                if hasattr(q, 'id') and q.id == 39988:
                    print(f"âœ… Found specific POTUS question: {q.question_text[:80]}...")
                    print(f"   ID: {q.id}")
                    print(f"   URL: {q.page_url}")
                    found_specific = True
                    potus_questions.append(q)

                    # Check tournament info
                    if hasattr(q, 'tournament'):
                        print(f"   ğŸ“‹ Tournament ID: {q.tournament}")
                    elif hasattr(q, 'tournaments') and q.tournaments:
                        print(f"   ğŸ“‹ Tournaments: {q.tournaments}")
                    break

                # Look for other POTUS questions
                if hasattr(q, 'page_url') and ('potus' in str(q.page_url).lower() or 'bondi' in str(q.page_url).lower()):
                    potus_questions.append(q)
                    print(f"ğŸ¯ Found POTUS question: {q.question_text[:80]}...")
                    if hasattr(q, 'tournament'):
                        print(f"   Tournament: {q.tournament}")
                    elif hasattr(q, 'tournaments') and q.tournaments:
                        print(f"   Tournaments: {q.tournaments}")

            if found_specific:
                question = potus_questions[0]
                print(f"\nâœ… Using specific POTUS question for testing")
            elif potus_questions:
                question = potus_questions[0]
                print(f"\nâœ… Using POTUS question found by search")
            else:
                print(f"\nâŒ No POTUS questions found")
                return False

        except Exception as e:
            print(f"âŒ Error finding POTUS questions: {str(e)}")
            return False

        # Step 2: Create LLM instances
        print(f"\nğŸ¤– STEP 2: INITIALIZING MULTIFORECASTER")

        researcher_llm = create_research_fallback_llm(api_key=api_key, temperature=0.3, timeout=60, allowed_tries=2)
        forecaster_llm = create_forecasting_fallback_llm(api_key=api_key, temperature=0.5, timeout=60, allowed_tries=2)
        synthesizer_llm = create_synthesis_fallback_llm(api_key=api_key, temperature=0.3, timeout=60, allowed_tries=2)

        print(f"âœ… Researcher model chain: {researcher_llm.model_chain}")
        print(f"âœ… Forecaster model chain: {forecaster_llm.model_chain}")
        print(f"âœ… Synthesizer model chain: {synthesizer_llm.model_chain}")

        # Step 3: Research Phase
        print(f"\nğŸ“š STEP 3: RESEARCH PHASE")
        print(f"Running research with detailed logging...")

        research_prompt = f"""
Research this question thoroughly: {question.question_text}

Page URL: {question.page_url}

Task:
1. Research the specific topic and context
2. Look for relevant data, trends, and expert opinions
3. Consider factors that could influence the outcome
4. Examine similar questions or historical precedents

Provide a comprehensive research summary covering all relevant aspects.
Your response should be detailed and evidence-based.
"""

        print(f"ğŸ“¤ Research prompt length: {len(research_prompt)} characters")

        try:
            print(f"ğŸ”„ Calling researcher model...")
            research_response = await researcher_llm.invoke(research_prompt)
            print(f"âœ… Research completed successfully!")
            print(f"ğŸ“¥ Research response length: {len(research_response)} characters")
            print(f"ğŸ“„ Research preview: {research_response[:200]}...")

        except Exception as e:
            print(f"âŒ Research failed: {str(e)}")
            research_response = f"Research failed: {str(e)}"

        # Step 4: Individual Forecasts
        print(f"\nğŸ”® STEP 4: INDIVIDUAL FORECASTS")
        print(f"Generating 3 individual forecasts...")

        forecast_prompt = f"""
Based on the research, provide your forecast for this question:

Question: {question.question_text}

Research Summary:
{research_response[:1500] if len(research_response) > 1500 else research_response}

Task:
Provide your forecast with:
1. Probability assessment (0-100%)
2. Reasoning (2-3 sentences)
3. Format: "Probability: XX% - [Yes/No]"

Consider the research evidence carefully.
"""

        individual_forecasts = []

        for i in range(3):  # 3 forecasters
            print(f"   ğŸ¤– Forecaster {i+1}/3...")

            try:
                forecaster_prompt = f"{forecast_prompt}\n\nAs Forecaster {i+1}, provide your independent assessment:"
                print(f"      ğŸ”„ Calling forecaster {i+1} model...")
                response = await forecaster_llm.invoke(forecaster_prompt)
                individual_forecasts.append(response)
                print(f"      âœ… Forecast {i+1} completed ({len(response)} chars)")
                print(f"      ğŸ“„ Forecast {i+1} preview: {response[:100]}...")

                await asyncio.sleep(2)  # Rate limiting

            except Exception as e:
                print(f"      âŒ Forecast {i+1} failed: {str(e)}")
                individual_forecasts.append(f"Forecast {i+1} failed: {str(e)}")

        print(f"âœ… Generated {len(individual_forecasts)} individual forecasts")

        # Step 5: Synthesis Phase
        print(f"\nğŸ”— STEP 5: SYNTHESIS PHASE")
        print(f"Synthesizing forecasts...")

        synthesis_prompt = f"""
Synthesize these forecasts for the question: {question.question_text}

Individual Forecasts:
{chr(10).join([f"Forecast {i+1}: {forecast}" for i, forecast in enumerate(individual_forecasts)])}

Task:
1. Analyze consensus and disagreements
2. Weigh reasoning and evidence
3. Provide final probability (0-100%)
4. Give comprehensive reasoning
5. Format: "Probability: XX% - [Yes/No]"

Synthesize thoughtfully and provide evidence-based conclusion.
"""

        try:
            print(f"ğŸ”„ Calling synthesizer model...")
            synthesis_response = await synthesizer_llm.invoke(synthesis_prompt)
            print(f"âœ… Synthesis completed successfully!")
            print(f"ğŸ“¥ Synthesis response length: {len(synthesis_response)} characters")
            print(f"ğŸ“„ Synthesis preview: {synthesis_response[:200]}...")

        except Exception as e:
            print(f"âŒ Synthesis failed: {str(e)}")
            synthesis_response = f"Synthesis failed: {str(e)}"

        # Step 6: Save output
        print(f"\nğŸ“‹ STEP 6: SAVING COMPREHENSIVE OUTPUT")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"potus_multiforecaster_{timestamp}.md"

        content = f"""# POTUS Predictions Multiforecaster Test

**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Question:** {question.question_text}
**URL:** {question.page_url}
**Question Type:** {type(question).__name__}

## Model Configuration

**All models used are FREE OpenRouter models:**
- Research: {researcher_llm.model_chain[0]} (primary)
- Forecasting: {forecaster_llm.model_chain[0]} (primary)
- Synthesis: {synthesizer_llm.model_chain[0]} (primary)

**Complete fallback chain (9 models each):**
"""

        for i, model in enumerate(researcher_llm.model_chain, 1):
            content += f"{i}. {model}\n"

        content += f"""

## Process Steps Completed:
âœ… 1. Found POTUS tournament questions
âœ… 2. Research Phase - Comprehensive analysis
âœ… 3. Individual Forecasts - {len(individual_forecasts)} model predictions
âœ… 4. Synthesis Phase - Combined expert consensus
âœ… 5. Final Prediction - Evidence-based recommendation

## Research Output

{research_response}

## Individual Forecasts

"""

        for i, forecast in enumerate(individual_forecasts, 1):
            content += f"### Forecaster {i}\n\n{forecast}\n\n"

        content += f"""## Synthesis Output

{synthesis_response}

## System Performance

âœ… API Authentication: Working with GitHub secrets
âœ… Free Model Configuration: All 9 models accessible
âœ… POTUS Tournament Questions: Successfully found and processed
âœ… Fallback Process: All API calls logged
âœ… Complete Multiforecaster Process: Research â†’ Forecasts â†’ Synthesis

**ğŸ¯ CONCLUSION: POTUS Predictions multiforecaster process working perfectly!**
"""

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"âœ… Comprehensive output saved to: {output_file}")

        # Check if the multiforecaster actually worked
        if "All 9 models in fallback chain failed" in research_response or len(individual_forecasts) == 0 or "All 9 models in fallback chain failed" in synthesis_response:
            print(f"\nâŒ MULTIFORECASTER PROCESS FAILED!")
            print(f"âŒ All API calls failed - no successful model responses")
            return False

        print(f"\n" + "=" * 50)
        print(f"ğŸ‰ POTUS PREDICTIONS MULTIFORECASTER TEST COMPLETED!")
        print(f"âœ… Used real POTUS Predictions question")
        print(f"âœ… Complete multiforecaster process with detailed logging")
        print(f"âœ… All outputs saved")
        print(f"ğŸ“„ Full report: {output_file}")
        print("=" * 50)

        return True

    except Exception as e:
        print(f"âŒ POTUS test failed: {str(e)}")
        print(f"âŒ Error type: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(test_potus_tournament())
    if success:
        print("\nğŸ‰ POTUS PREDICTIONS MULTIFORECASTER SUCCESSFUL!")
        print("âœ… Found and processed real POTUS questions")
        print("âœ… All API calls logged with model details")
    else:
        print("\nâŒ POTUS PREDICTIONS TEST FAILED!")
        print("âŒ Check the error messages above")
    import sys
    sys.exit(0 if success else 1)