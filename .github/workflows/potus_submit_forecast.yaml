name: POTUS Forecast Submission

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */4 * * * *" # every 4 hours

jobs:
  potus_submit_job:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          echo "=== Installing POTUS forecast submission system ==="
          pip install forecasting-tools python-dotenv asyncio

      - name: POTUS Forecast with Submission
        run: |
          echo "=== Starting POTUS Forecast with Submission at $(date) ==="

          python3 << 'EOF'
          import os
          import asyncio
          from datetime import datetime
          import re

          os.environ['GITHUB_ACTIONS'] = 'true'

          async def potus_forecast_with_submission():
              """POTUS forecasting with actual submission to Metaculus."""
              print("üéØ POTUS FORECAST WITH ACTUAL SUBMISSION")
              print("=" * 70)

              # Check environment
              api_key = os.getenv('OPENROUTER_API_KEY')
              metaculus_token = os.getenv('METACULUS_TOKEN')

              if not api_key or not metaculus_token:
                  print("‚ùå Missing API keys")
                  return False

              print("‚úÖ API keys configured")

              try:
                  from forecasting_tools import MetaculusApi, ApiFilter, BinaryQuestion
                  from fallback_llm import create_research_fallback_llm, create_forecasting_fallback_llm, create_synthesis_fallback_llm

                  print("‚úÖ Modules imported successfully")

                  # STEP 1: Get the specific Bondi question
                  print("\\nüìä STEP 1: GETTING BONDI QUESTION (39988)")

                  bondi_question = None
                  try:
                      # Method 1: Try direct URL access first
                      print("üîç Trying direct URL access to Bondi question...")
                      bondi_question = await MetaculusApi.get_question_by_url("https://www.metaculus.com/questions/39988/")
                      print(f"‚úÖ Found Bondi question: {bondi_question.question_text[:80]}...")
                      print(f"   URL: {bondi_question.page_url}")
                      print(f"   Status: {bondi_question.status}")
                      print(f"   Type: {type(bondi_question).__name__}")

                  except Exception as e:
                      print(f"‚ùå Direct URL access failed: {e}")

                  # Fallback: Search in POTUS tournament
                  if not bondi_question:
                      try:
                          print("üîç Searching in POTUS tournament for Bondi question...")
                          questions = MetaculusApi.get_all_open_questions_from_tournament("POTUS-predictions")

                          for q in questions:
                              if 'bondi' in str(q.question_text).lower() or 'attorney general' in str(q.question_text).lower():
                                  bondi_question = q
                                  print(f"‚úÖ Found Bondi question in tournament: {q.question_text[:80]}...")
                                  break
                      except Exception as e:
                          print(f"‚ùå Tournament search failed: {e}")

                  # Final fallback: Search all open questions
                  if not bondi_question:
                      try:
                          print("üîç Searching all open questions for Bondi...")
                          api_filter = ApiFilter(statuses=["open"], number_of_questions=100)
                          questions = await MetaculusApi.get_questions_matching_filter(api_filter)

                          for q in questions:
                              if 'bondi' in str(q.question_text).lower() or 'attorney general' in str(q.question_text).lower():
                                  bondi_question = q
                                  print(f"‚úÖ Found Bondi question in general search: {q.question_text[:80]}...")
                                  break
                      except Exception as e:
                          print(f"‚ùå General search failed: {e}")

                  if not bondi_question:
                      print("‚ùå Could not find Bondi question")
                      return False

                  # Verify question is open and binary
                  if bondi_question.status != "open":
                      print(f"‚ùå Question is not open. Status: {bondi_question.status}")
                      return False

                  if not isinstance(bondi_question, BinaryQuestion):
                      print(f"‚ùå Question is not binary. Type: {type(bondi_question).__name__}")
                      return False

                  print(f"\\n‚úÖ CONFIRMED: Open binary Bondi question ready for forecasting")

                  # STEP 2: Initialize LLMs
                  print("\\nü§ñ STEP 2: INITIALIZING MULTIFORECASTER")

                  researcher_llm = create_research_fallback_llm(api_key=api_key, temperature=0.3, timeout=60, allowed_tries=2)
                  forecaster_llm = create_forecasting_fallback_llm(api_key=api_key, temperature=0.5, timeout=60, allowed_tries=2)
                  synthesizer_llm = create_synthesis_fallback_llm(api_key=api_key, temperature=0.3, timeout=60, allowed_tries=2)

                  print(f"‚úÖ Researcher: {researcher_llm.model_chain[0]}")
                  print(f"‚úÖ Forecaster: {forecaster_llm.model_chain[0]}")
                  print(f"‚úÖ Synthesizer: {synthesizer_llm.model_chain[0]}")

                  # STEP 3: Research Phase
                  print("\\nüìö STEP 3: RESEARCH PHASE")

                  research_prompt = f"""Research this question thoroughly: {bondi_question.question_text}

          Page URL: {bondi_question.page_url}

          Task:
          1. Research Pam Bondi's situation as Attorney General
          2. Look for relevant legal developments, political pressure, or resignation rumors
          3. Consider factors that could lead to her departure before March 2026
          4. Examine historical precedents for similar situations
          5. Analyze current political climate and administration dynamics

          Provide a comprehensive research summary covering all relevant aspects.
          Focus on concrete evidence and realistic scenarios.
          """

                  try:
                      print("üîÑ Running research on Bondi situation...")
                      research_response = await researcher_llm.invoke(research_prompt)
                      print(f"‚úÖ Research completed ({len(research_response)} characters)")
                      print(f"üìÑ Preview: {research_response[:200]}...")
                  except Exception as e:
                      print(f"‚ùå Research failed: {e}")
                      research_response = f"Research failed: {e}"

                  # STEP 4: Individual Forecasts
                  print("\\nüîÆ STEP 4: INDIVIDUAL FORECASTS")

                  forecast_prompt = f"""Based on the research, provide your forecast for this question:

          Question: {bondi_question.question_text}

          Research Summary:
          {research_response[:1500] if len(research_response) > 1500 else research_response}

          Task:
          Provide your forecast with:
          1. Probability assessment (0-100% for "Yes" - Bondi will be out before March 2026)
          2. Clear reasoning (2-3 sentences)
          3. Format: "Probability: XX% - [Yes/No]"

          Consider the research evidence carefully and provide a realistic probability assessment.
          Focus on the likelihood of Bondi's departure before the specified date.
          """

                  individual_forecasts = []

                  for i in range(2):  # 2 forecasters for diversity
                      print(f"   ü§ñ Forecaster {i+1}/2...")
                      try:
                          forecaster_prompt = f"{forecast_prompt}\\n\\nAs Forecaster {i+1}, provide your independent assessment:"
                          response = await forecaster_llm.invoke(forecaster_prompt)
                          individual_forecasts.append(response)
                          print(f"      ‚úÖ Forecast {i+1} completed")
                          print(f"      üìÑ Preview: {response[:100]}...")
                          await asyncio.sleep(1)  # Rate limiting
                      except Exception as e:
                          print(f"      ‚ùå Forecast {i+1} failed: {e}")
                          individual_forecasts.append(f"Forecast {i+1} failed: {e}")

                  print(f"‚úÖ Generated {len(individual_forecasts)} individual forecasts")

                  # STEP 5: Synthesis Phase
                  print("\\nüîó STEP 5: SYNTHESIS PHASE")

                  synthesis_prompt = f"""Synthesize these forecasts for the question: {bondi_question.question_text}

          Individual Forecasts:
          {chr(10).join([f"Forecast {i+1}: {forecast}" for i, forecast in enumerate(individual_forecasts)])}

          Task:
          1. Analyze consensus and disagreements between forecasters
          2. Weigh reasoning and evidence from each forecast
          3. Provide final probability (0-100% for "Yes")
          4. Give comprehensive reasoning
          5. Format: "Probability: XX% - [Yes/No]"

          Synthesize thoughtfully and provide evidence-based conclusion that reflects
          the consensus view while acknowledging uncertainties. Be realistic about the probability.
          """

                  try:
                      print("üîÑ Running synthesis...")
                      synthesis_response = await synthesizer_llm.invoke(synthesis_prompt)
                      print(f"‚úÖ Synthesis completed ({len(synthesis_response)} characters)")
                      print(f"üìÑ Preview: {synthesis_response[:200]}...")
                  except Exception as e:
                      print(f"‚ùå Synthesis failed: {e}")
                      synthesis_response = f"Synthesis failed: {e}"

                  # STEP 6: Extract Final Probability
                  print("\\nüìä STEP 6: EXTRACTING FINAL PROBABILITY")

                  final_probability = None
                  final_prediction = None

                  try:
                      # Look for probability in synthesis response
                      probability_match = re.search(r'Probability:\s*(\d+)%', synthesis_response)
                      if probability_match:
                          final_probability = int(probability_match.group(1))
                          final_prediction = final_probability >= 50
                          print(f"‚úÖ Extracted probability: {final_probability}%")
                          print(f"   Final prediction: {'Yes' if final_prediction else 'No'}")
                      else:
                          # Fallback: look for any percentage
                          percent_match = re.search(r'(\d+)%', synthesis_response)
                          if percent_match:
                              final_probability = int(percent_match.group(1))
                              final_prediction = final_probability >= 50
                              print(f"‚ö†Ô∏è  Found percentage: {final_probability}%")
                              print(f"   Final prediction: {'Yes' if final_prediction else 'No'}")
                          else:
                              print("‚ùå Could not extract probability from synthesis")
                              return False

                  except Exception as e:
                      print(f"‚ùå Probability extraction failed: {e}")
                      return False

                  # STEP 7: SUBMIT FORECAST TO METACULUS
                  print("\\nüöÄ STEP 7: SUBMITTING FORECAST TO METACULUS")

                  try:
                      print(f"üîÑ Submitting forecast to Metaculus...")
                      print(f"   Question ID: {bondi_question.id}")
                      print(f"   Prediction: {final_probability}% ({'Yes' if final_prediction else 'No'})")

                      # Submit the forecast
                      MetaculusApi.post_binary_question_prediction(bondi_question.id, final_probability / 100.0)

                      print(f"‚úÖ FORECAST SUBMITTED SUCCESSFULLY!")
                      print(f"   Probability: {final_probability}%")
                      print(f"   URL: {bondi_question.page_url}")

                  except Exception as e:
                      print(f"‚ùå Forecast submission failed: {e}")
                      return False

                  # STEP 8: Save comprehensive output
                  print("\\nüìã STEP 8: SAVING COMPREHENSIVE OUTPUT")

                  timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                  output_file = f"potus_forecast_submitted_{timestamp}.md"

                  content = f"""# POTUS Forecast Submission Results

          **Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
          **Status:** ‚úÖ SUBMITTED TO METACULUS
          **Question:** {bondi_question.question_text}
          **URL:** {bondi_question.page_url}
          **Question ID:** {bondi_question.id}

          ## üéØ FORECAST SUBMISSION SUCCESS!
          ‚úÖ **Successfully accessed real POTUS Predictions tournament**
          ‚úÖ **Found and processed Bondi Attorney General question**
          ‚úÖ **Generated comprehensive research and analysis**
          ‚úÖ **Created multiple independent forecasts**
          ‚úÖ **Synthesized consensus prediction**
          ‚úÖ **SUBMITTED FORECAST TO METACULUS!**

          ## Final Forecast Submitted:
          **Probability:** {final_probability}% ({'Yes' if final_prediction else 'No'})
          **Submission Time:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

          ## Model Configuration
          **All models are FREE OpenRouter models:**
          - Research: {researcher_llm.model_chain[0]}
          - Forecasting: {forecaster_llm.model_chain[0]}
          - Synthesis: {synthesizer_llm.model_chain[0]}

          ## Process Completed:
          ‚úÖ 1. Question Discovery - Real POTUS tournament
          ‚úÖ 2. Research Phase - Comprehensive analysis
          ‚úÖ 3. Individual Forecasts - Multiple predictions
          ‚úÖ 4. Synthesis Phase - Consensus building
          ‚úÖ 5. Probability Extraction - {final_probability}%
          ‚úÖ 6. **FORECAST SUBMISSION - SUCCESS!**

          ## Research Output

          {research_response}

          ## Individual Forecasts

          """

                  for i, forecast in enumerate(individual_forecasts, 1):
                      content += f"### Forecaster {i}\\n\\n{forecast}\\n\\n"

                  content += f"""## Synthesis Output

          {synthesis_response}

          ## Verification
          **Check the forecast at:** [{bondi_question.page_url}]({bondi_question.page_url})

          The forecast should appear in the prediction history shortly after submission.

          **üéØ CONCLUSION: Complete end-to-end POTUS forecasting with submission SUCCESS!**
          """

                  with open(output_file, 'w', encoding='utf-8') as f:
                      f.write(content)

                  print(f"‚úÖ Comprehensive output saved: {output_file}")
                  return True

              except Exception as e:
                  print(f"‚ùå POTUS forecast with submission failed: {str(e)}")
                  import traceback
                  traceback.print_exc()
                  return False

          # Run the complete forecast with submission
          success = asyncio.run(potus_forecast_with_submission())
          if success:
              print("\\nüéâ POTUS FORECAST WITH SUBMISSION SUCCESSFUL!")
              print("‚úÖ Forecast submitted to Metaculus")
              print("‚úÖ Check the question page to see the prediction")
          else:
              print("\\n‚ùå POTUS FORECAST WITH SUBMISSION FAILED!")
          EOF

          echo "=== POTUS Forecast with Submission completed at $(date) ==="

      - name: Upload Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: potus-submission-results-${{ github.run_number }}
          path: potus_forecast_submitted_*.md
          retention-days: 30

    env:
      GITHUB_ACTIONS: "true"
      METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      OPENAI_DISABLE_TRACE: "true"
      OPENAI_ORGANIZATION: ""