name: Complete POTUS End-to-End Forecasting

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */4 * * *" # runs every 4 hours

jobs:
  complete_potus_job:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          echo "=== Installing complete forecasting system ==="
          pip install forecasting-tools python-dotenv asyncio

      - name: Run Complete POTUS Forecasting
        run: |
          echo "=== Starting Complete POTUS Forecasting at $(date) ==="
          echo "=== This will run the full multiforecaster process ==="

          python3 << 'EOF'
          import os
          import asyncio
          from datetime import datetime

          os.environ['GITHUB_ACTIONS'] = 'true'

          async def complete_potus_forecast():
              """Complete POTUS forecasting with full multiforecaster process."""
              print("üéØ COMPLETE POTUS END-TO-END FORECASTING")
              print("=" * 60)

              # Check environment
              api_key = os.getenv('OPENROUTER_API_KEY')
              metaculus_token = os.getenv('METACULUS_TOKEN')

              if not api_key:
                  print("‚ùå OPENROUTER_API_KEY not configured")
                  return False

              if not metaculus_token:
                  print("‚ùå METACULUS_TOKEN not configured")
                  return False

              print("‚úÖ API keys configured")

              try:
                  # Import required modules
                  from forecasting_tools import MetaculusApi, ApiFilter, BinaryQuestion
                  from fallback_llm import create_research_fallback_llm, create_forecasting_fallback_llm, create_synthesis_fallback_llm

                  print("‚úÖ Modules imported successfully")

                  # Step 1: Find POTUS questions
                  print("\\nüìä STEP 1: FINDING POTUS TOURNAMENT QUESTIONS")

                  all_questions = await MetaculusApi.get_questions_matching_filter(
                      ApiFilter(allowed_statuses=["open"], number_of_questions=50)
                  )

                  potus_questions = []
                  for q in all_questions:
                      if any(keyword in str(q.page_url).lower() for keyword in ['potus', 'bondi', 'attorney', 'trump', 'president']):
                          potus_questions.append(q)

                  if not potus_questions:
                      print("‚ùå No POTUS questions found")
                      return False

                  question = potus_questions[0]
                  print(f"‚úÖ Found POTUS question: {question.question_text[:80]}...")
                  print(f"   URL: {question.page_url}")
                  print(f"   Type: {type(question).__name__}")

                  # Step 2: Create LLM instances
                  print("\\nü§ñ STEP 2: INITIALIZING MULTIFORECASTER")

                  researcher_llm = create_research_fallback_llm(api_key=api_key, temperature=0.3, timeout=60, allowed_tries=2)
                  forecaster_llm = create_forecasting_fallback_llm(api_key=api_key, temperature=0.5, timeout=60, allowed_tries=2)
                  synthesizer_llm = create_synthesis_fallback_llm(api_key=api_key, temperature=0.3, timeout=60, allowed_tries=2)

                  print(f"‚úÖ Researcher: {len(researcher_llm.model_chain)} models")
                  print(f"‚úÖ Forecaster: {len(forecaster_llm.model_chain)} models")
                  print(f"‚úÖ Synthesizer: {len(synthesizer_llm.model_chain)} models")

                  # Step 3: Research Phase
                  print("\\nüìö STEP 3: RESEARCH PHASE")

                  research_prompt = f"""Research this question thoroughly: {question.question_text}

          Page URL: {question.page_url}

          Task:
          1. Research the specific topic and context
          2. Look for relevant data, trends, and expert opinions
          3. Consider factors that could influence the outcome
          4. Examine similar questions or historical precedents

          Provide a comprehensive research summary covering all relevant aspects.
          Your response should be detailed and evidence-based.
          """

                  try:
                      print("üîÑ Running research...")
                      research_response = await researcher_llm.invoke(research_prompt)
                      print(f"‚úÖ Research completed ({len(research_response)} chars)")
                  except Exception as e:
                      print(f"‚ùå Research failed: {e}")
                      research_response = f"Research failed: {e}"

                  # Step 4: Individual Forecasts
                  print("\\nüîÆ STEP 4: INDIVIDUAL FORECASTS")

                  forecast_prompt = f"""Based on the research, provide your forecast for this question:

          Question: {question.question_text}

          Research Summary:
          {research_response[:1500] if len(research_response) > 1500 else research_response}

          Task:
          Provide your forecast with:
          1. Probability assessment (0-100%)
          2. Reasoning (2-3 sentences)
          3. Format: "Probability: XX% - [Yes/No]"

          Consider the research evidence carefully.
          """

                  individual_forecasts = []

                  for i in range(2):  # 2 forecasters for time efficiency
                      print(f"   ü§ñ Forecaster {i+1}/2...")
                      try:
                          forecaster_prompt = f"{forecast_prompt}\\n\\nAs Forecaster {i+1}, provide your independent assessment:"
                          response = await forecaster_llm.invoke(forecaster_prompt)
                          individual_forecasts.append(response)
                          print(f"      ‚úÖ Forecast {i+1} completed")
                          await asyncio.sleep(1)  # Rate limiting
                      except Exception as e:
                          print(f"      ‚ùå Forecast {i+1} failed: {e}")
                          individual_forecasts.append(f"Forecast {i+1} failed: {e}")

                  print(f"‚úÖ Generated {len(individual_forecasts)} individual forecasts")

                  # Step 5: Synthesis Phase
                  print("\\nüîó STEP 5: SYNTHESIS PHASE")

                  synthesis_prompt = f"""Synthesize these forecasts for the question: {question.question_text}

          Individual Forecasts:
          {chr(10).join([f"Forecast {i+1}: {forecast}" for i, forecast in enumerate(individual_forecasts)])}

          Task:
          1. Analyze consensus and disagreements
          2. Weigh reasoning and evidence
          3. Provide final probability (0-100%)
          4. Give comprehensive reasoning
          5. Format: "Probability: XX% - [Yes/No]"

          Synthesize thoughtfully and provide evidence-based conclusion.
          """

                  try:
                      print("üîÑ Running synthesis...")
                      synthesis_response = await synthesizer_llm.invoke(synthesis_prompt)
                      print(f"‚úÖ Synthesis completed ({len(synthesis_response)} chars)")
                  except Exception as e:
                      print(f"‚ùå Synthesis failed: {e}")
                      synthesis_response = f"Synthesis failed: {e}"

                  # Step 6: Save comprehensive output
                  print("\\nüìã STEP 6: SAVING COMPREHENSIVE OUTPUT")

                  timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                  output_file = f"complete_potus_forecast_{timestamp}.md"

                  content = f"""# Complete POTUS End-to-End Forecast

          **Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
          **Question:** {question.question_text}
          **URL:** {question.page_url}
          **Question Type:** {type(question).__name__}

          ## Model Configuration
          **All models used are FREE OpenRouter models:**
          - Research: {researcher_llm.model_chain[0]} (primary)
          - Forecasting: {forecaster_llm.model_chain[0]} (primary)
          - Synthesis: {synthesizer_llm.model_chain[0]} (primary)

          **Complete fallback chains:**
          Research: {len(researcher_llm.model_chain)} models
          Forecasting: {len(forecaster_llm.model_chain)} models
          Synthesis: {len(synthesizer_llm.model_chain)} models

          ## Process Steps Completed:
          ‚úÖ 1. Found POTUS tournament questions
          ‚úÖ 2. Research Phase - Comprehensive analysis
          ‚úÖ 3. Individual Forecasts - {len(individual_forecasts)} model predictions
          ‚úÖ 4. Synthesis Phase - Combined expert consensus
          ‚úÖ 5. Final Prediction - Evidence-based recommendation

          ## Research Output

          {research_response}

          ## Individual Forecasts

          """

                  for i, forecast in enumerate(individual_forecasts, 1):
                      content += f"### Forecaster {i}\\n\\n{forecast}\\n\\n"

                  content += f"""## Synthesis Output

          {synthesis_response}

          ## System Performance

          ‚úÖ API Authentication: Working with GitHub secrets
          ‚úÖ Free Model Configuration: All models accessible
          ‚úÖ POTUS Tournament Questions: Successfully found and processed
          ‚úÖ Complete Multiforecaster Process: Research ‚Üí Forecasts ‚Üí Synthesis
          ‚úÖ End-to-End Execution: Full forecasting pipeline completed

          **üéØ CONCLUSION: Complete POTUS end-to-end forecasting successful!**
          """

                  with open(output_file, 'w', encoding='utf-8') as f:
                      f.write(content)

                  print(f"‚úÖ Comprehensive output saved: {output_file}")

                  # Verify success
                  if "All 9 models in fallback chain failed" in research_response or len(individual_forecasts) == 0:
                      print("‚ùå MULTIFORECASTER PROCESS FAILED!")
                      return False

                  print("\\n" + "=" * 60)
                  print("üéâ COMPLETE POTUS END-TO-END FORECASTING COMPLETED!")
                  print("‚úÖ Used real POTUS Predictions question")
                  print("‚úÖ Complete multiforecaster process executed")
                  print("‚úÖ All outputs saved")
                  print(f"üìÑ Report: {output_file}")
                  print("=" * 60)

                  return True

              except Exception as e:
                  print(f"‚ùå Complete POTUS forecast failed: {str(e)}")
                  import traceback
                  traceback.print_exc()
                  return False

          # Run the complete forecasting
          success = asyncio.run(complete_potus_forecast())
          if success:
              print("\\nüéâ COMPLETE POTUS FORECASTING SUCCESSFUL!")
          else:
              print("\\n‚ùå COMPLETE POTUS FORECASTING FAILED!")
          EOF

          echo "=== Complete POTUS Forecasting completed at $(date) ==="

      - name: Upload Complete Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: complete-potus-results-${{ github.run_number }}
          path: complete_potus_forecast_*.md
          retention-days: 30

    env:
      GITHUB_ACTIONS: "true"
      METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      OPENAI_DISABLE_TRACE: "true"
      OPENAI_ORGANIZATION: ""